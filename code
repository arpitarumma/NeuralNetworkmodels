# import the necessary packages
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.datasets import mnist
from tensorflow.keras import backend as K
import matplotlib.pyplot as plt
import numpy as np
import argparse
# Handle argument parsing
import argparse
import sys  # Import the sys module

# Create an argument parser
ap = argparse.ArgumentParser()
ap.add_argument("-o", "--output", required=False, default="output_plot.png", help="path to the output loss/accuracy plot")
# Check if the script is being run from a notebook or terminal
args = vars(ap.parse_args(args=[] if sys.argv[1:] else ["--output", "output_plot.png"]))
# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Preprocess data
x_train = x_train / 255.0  # Normalize pixel values to between 0 and 1
x_test = x_test / 255.0

# Flatten the images to a 1D array of 28*28=784 pixels
x_train = x_train.reshape(-1, 28*28)
x_test = x_test.reshape(-1, 28*28)
# Convert labels to one-hot encoded vectors using LabelBinarizer
lb = LabelBinarizer()
y_train = lb.fit_transform(y_train)  # One-hot encode the training labels
y_test = lb.transform(y_test)  # One-hot encode the test labels
print(y_train)  # Print the array to the console
# Or, to view a portion of the array:
print(y_train[:5])  # Print the first 5 rows of the array
model = Sequential()

# Input layer (input shape is 784, since MNIST images are 28x28 pixels)
model.add(Dense(128, activation='relu', input_shape=(784,)))

# Hidden layer
model.add(Dense(64, activation='relu'))

# Output layer (10 units for 10 classes, softmax for classification)
model.add(Dense(10, activation='softmax'))
model.compile(optimizer=SGD(),
              loss='categorical_crossentropy',  # Changed loss function
              metrics=['accuracy'])
  model.fit(x_train, y_train, epochs=5, batch_size=32)
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f'Test accuracy: {test_acc}')
  predictions = model.predict(x_test)

# Print the predicted class for the first test image
print(f'Predicted label for the first image: {predictions[0].argmax()}')
# Evaluate the model and make predictions
print("[INFO] evaluating network...")
predictions = model.predict(x_test, batch_size=128)

# Generate the classification report
print(classification_report(y_test.argmax(axis=1),
                            predictions.argmax(axis=1),
                            target_names=[str(x) for x in lb.classes_]))
# Load the MNIST dataset
print("[INFO] accessing MNIST...")
((trainX, trainY), (testX, testY)) = mnist.load_data()

# Reshape and scale the data
trainX = trainX.reshape((trainX.shape[0], 28 * 28 * 1)).astype("float32") / 255.0
testX = testX.reshape((testX.shape[0], 28 * 28 * 1)).astype("float32") / 255.0

# Convert labels to one-hot encoded vectors
lb = LabelBinarizer()
trainY = lb.fit_transform(trainY)
testY = lb.transform(testY)

# Define the neural network architecture
model = Sequential([
    Dense(256, input_shape=(784,), activation="sigmoid"),
    Dense(128, activation="sigmoid"),
    Dense(10, activation="softmax")
])

# Compile the model
print("[INFO] training network...")
sgd = SGD(learning_rate=0.01)
model.compile(loss="categorical_crossentropy", optimizer=sgd, metrics=["accuracy"])

# Train the model
H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=100, batch_size=128)

# Evaluate the model
print("[INFO] evaluating network...")
predictions = model.predict(testX, batch_size=128)
print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=[str(x) for x in lb.classes_]))

# Plot the training loss and accuracy
N = np.arange(0, 100)
plt.style.use("ggplot")
plt.figure()
plt.plot(N, H.history["loss"], label="train_loss")
plt.plot(N, H.history["val_loss"], label="val_loss")
plt.plot(N, H.history["accuracy"], label="train_acc")
plt.plot(N, H.history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend()
plt.savefig(args["output"])
  
